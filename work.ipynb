{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jemie-tech/data-covid/blob/main/work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cleaning techniques**"
      ],
      "metadata": {
        "id": "F0NF249kb45D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Creating a sample DataFrame with missing values\n",
        "data = {\n",
        "    'A': [1, 2, np.nan, 4, 5],\n",
        "    'B': [np.nan, 2, 3, 4, 5],\n",
        "    'C': [1, 2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "-g_G03EhcATg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Drop rows with any missing values**\n",
        "\n",
        "This method drops any row containing at least one missing value. It's a straightforward approach, but it might lead to a significant loss of data if there are many missing values."
      ],
      "metadata": {
        "id": "-ZYDOVKvtIGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any missing values\n",
        "df_dropped = df.dropna()\n"
      ],
      "metadata": {
        "id": "a6HkbgORqMgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Filling Missing Values:**\n",
        "\n",
        "**Forward Fill (ffill)**: This method fills missing values with the preceding non-missing value in the column. It is useful when missing values are expected to have the same value as the previous entry.\n",
        "\n",
        "**Backward Fill (bfill)**: This method fills missing values with the next non-missing value in the column. It is useful when missing values are expected to have the same value as the following entry.\n",
        "\n",
        "\n",
        "**Mean Fill**: Filling missing values with the mean of the column. It is suitable for continuous numerical data.\n",
        "\n",
        "**Median Fill:** Filling missing values with the median of the column. It is robust to outliers and is also suitable for numerical data.\n",
        "\n",
        "**Mode Fill:** Filling missing values with the mode (most frequent value) of the column. It is suitable for categorical or discrete data."
      ],
      "metadata": {
        "id": "cO890DDMtvgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward fill missing values\n",
        "df_forward_filled = df.ffill()\n",
        "\n",
        "# Backward fill missing values\n",
        "df_backward_filled = df.bfill()\n",
        "\n",
        "# Fill missing values with a specific value (e.g., mean, median, mode)\n",
        "df_mean_filled = df.fillna(df.mean())\n",
        "df_median_filled = df.fillna(df.median())\n",
        "df_mode_filled = df.fillna(df.mode().iloc[0])\n"
      ],
      "metadata": {
        "id": "WCjaRB7ntvAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Interpolation:**\n",
        "\n",
        "This method estimates missing values based on the values of other data points. In the case of time-series data, for example, it can fill in missing values by considering the trend between existing data points."
      ],
      "metadata": {
        "id": "JUVK3zWIxSc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear interpolation for missing values\n",
        "df_interpolated = df.interpolate()\n"
      ],
      "metadata": {
        "id": "9-CYhRf_xZm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Imputation with Scikit-Learn:**\n",
        "\n",
        "\n",
        "\n",
        "**SimpleImputer:** This is a class from Scikit-Learn that provides various strategies for imputing missing values.\n",
        "\n",
        "**Mean Imputation:** Filling missing values with the mean of the column.\n",
        "\n",
        "**Median Imputation:** Filling missing values with the median of the column.\n",
        "\n",
        "**Constant Imputation:** Filling missing values with a constant value (in this case, 0)."
      ],
      "metadata": {
        "id": "50RajawExpdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute missing values with mean, median, or a constant\n",
        "imputer_mean = SimpleImputer(strategy='mean')\n",
        "df_imputed_mean = pd.DataFrame(imputer_mean.fit_transform(df), columns=df.columns)\n",
        "\n",
        "imputer_median = SimpleImputer(strategy='median')\n",
        "df_imputed_median = pd.DataFrame(imputer_median.fit_transform(df), columns=df.columns)\n",
        "\n",
        "imputer_constant = SimpleImputer(strategy='constant', fill_value=0)\n",
        "df_imputed_constant = pd.DataFrame(imputer_constant.fit_transform(df), columns=df.columns)\n"
      ],
      "metadata": {
        "id": "t1T8AUbYxnw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Removing Duplicates:**\n",
        "\n",
        "This method removes duplicate rows from the DataFrame, keeping only the first occurrence. It is useful when dealing with datasets that may have duplicate entries. Be cautious when using this, as it can lead to a loss of potentially valuable data."
      ],
      "metadata": {
        "id": "kle9ulyFysZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows\n",
        "df_no_duplicates = df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "y_P9I-Ajyv7o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}